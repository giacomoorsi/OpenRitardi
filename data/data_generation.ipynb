{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code to generate some of the files used by our project website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "# Initial Spark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import explode\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.functions import lit, col, to_date\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql.functions import stddev\n",
    "from pyspark.sql.functions import count, countDistinct, concat, sum\n",
    "from pyspark.sql.functions import percentile_approx\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"/Users/giacomoorsi/MEGAsync Downloads/Trenitalia-GenMar2023\"\n",
    "file = \"all.parquet\"\n",
    "\n",
    "SAVE_COMPUTATIONS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/21 11:42:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .appName(\"Trenitalia\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# set driver memory to 4GB\n",
    "spark.sparkContext._conf.setAll([('spark.driver.memory', '4g')])\n",
    "\n",
    "# get sc \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:==============>                                            (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 8316723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(os.path.join(DATA_FOLDER, \"parquet\", file))\n",
    "print(\"Number of rows: {}\".format(df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset of the stops\n",
    "stops = spark.read.csv(os.path.join(DATA_FOLDER, \"stops.csv\"), header=True, inferSchema=True)\n",
    "\n",
    "stops_column_renamer = {\n",
    "    \"name\": \"stop_name\",\n",
    "    \"lat\": \"stop_lat\",\n",
    "    \"lon\": \"stop_lon\",\n",
    "    \"station_id\": \"stop_id\", \n",
    "    \"name_short\": \"stop_name_short\",\n",
    "    \"id_region\": \"stop_id_region\",\n",
    "}\n",
    "\n",
    "for k, v in stops_column_renamer.items():\n",
    "    stops = stops.withColumnRenamed(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days:  90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First date:  2023-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last date:  2023-03-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trains:  11496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stops:  2291\n",
      "Number of train classes:  11\n"
     ]
    }
   ],
   "source": [
    "# number of days\n",
    "print(\"Number of days: \", df.select(\"date\").distinct().count())\n",
    "\n",
    "# first date\n",
    "print(\"First date: \", df.select(\"date\").distinct().orderBy(\"date\").first().asDict()[\"date\"])\n",
    "\n",
    "# last date\n",
    "print(\"Last date: \", df.select(\"date\").distinct().orderBy(\"date\", ascending=False).first().asDict()[\"date\"])\n",
    "\n",
    "# number of trains\n",
    "print(\"Number of trains: \", df.select(\"train_number\").distinct().count())\n",
    "\n",
    "# number of stops\n",
    "print(\"Number of stops: \", df.select(\"stop_name\").distinct().count())\n",
    "\n",
    "# number of train classes\n",
    "print(\"Number of train classes: \", df.select(\"train_class\").distinct().count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_arrival_stop_name', 'train_class', 'train_cn', 'train_dl', 'train_number', 'train_arrival_time', 'oae', 'train_oaz', 'train_od', 'train_oo', 'train_departure_time', 'train_ope', 'train_opz', 'train_departure_stop_name', 'train_pr', 'train_arrival_delay', 'train_departure_delay', 'sea', 'train_sep', 'train_sub', 'day', 'month', 'year', 'date', 'stop_name', 'stop_arrival_time', 'stop_departure_time', 'stop_arrival_delay', 'stop_departure_delay']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preprocessing\n",
    "As step of preprocessing, we remove all delays that are anomalous, i.e. they are not in the range [-100, 300] minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all values of delays that are not in the range [-100, 300] if they are numerical\n",
    "MIN_DELAY = -100\n",
    "MAX_DELAY = 300\n",
    "df = df.filter((col(\"stop_arrival_delay\").cast(\"double\").isNull()) | (col(\"stop_arrival_delay\").cast(\"double\") >= MIN_DELAY) & (col(\"stop_arrival_delay\").cast(\"double\") <= MAX_DELAY))\n",
    "\n",
    "# remove all the trains that are not in the following classes\n",
    "KEEP_TRAIN_CLASSES = [\"IC\", \"ICN\", \"REG\", \"\", \"EC\"]\n",
    "\n",
    "df = df.filter(col(\"train_class\").isin(KEEP_TRAIN_CLASSES))\n",
    "\n",
    "# replace empty train class with \"AV\"\n",
    "df = df.withColumn(\"train_class\", F.when(col(\"train_class\") == \"\", \"AV\").otherwise(col(\"train_class\")))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Statistics for each station"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each distinct station, we want to obtain: \n",
    "1. Station name\n",
    "2. Latitude, longitude\n",
    "3. Average arrival delay\n",
    "4. Median arrival delay\n",
    "5. % of trains with delay > 3\n",
    "6. % of trains with delay > 5\n",
    "7. % of trains with delay > 10\n",
    "8. Number of distinct train numbers that stopped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column True if train had > 3 minutes of delay\n",
    "data_stop = df.join(stops, on=\"stop_name\", how=\"inner\")\n",
    "\n",
    "\n",
    "data_stop = data_stop \\\n",
    "    .filter(col(\"stop_arrival_delay\").cast(\"double\").isNotNull()) \\\n",
    "    .withColumn(\"stop_arrival_delay_double\", col(\"stop_arrival_delay\").cast(\"double\")) \\\n",
    "    .drop(\"stop_arrival_delay\") \\\n",
    "    .withColumnRenamed(\"stop_arrival_delay_double\", \"stop_arrival_delay\") \\\n",
    "    .withColumn(\"3m_delay\", col(\"stop_arrival_delay\") > 3)\\\n",
    "    .withColumn(\"5m_delay\", col(\"stop_arrival_delay\") > 5)\\\n",
    "    .withColumn(\"10m_delay\", col(\"stop_arrival_delay\") > 10)\\\n",
    "    .withColumn(\"day_of_week\", F.date_format(F.col(\"date\"), \"E\"))\\\n",
    "    .withColumn(\"train_id\", concat(col(\"train_class\"), col(\"train_number\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stop_stat = data_stop.groupBy(\"stop_name\") \\\n",
    "    .agg(\n",
    "        F.avg(\"stop_arrival_delay\").alias(\"avg_arrival_delay\"),\n",
    "        F.percentile_approx(\"stop_arrival_delay\", 0.5).alias(\"median_arrival_delay\"),\n",
    "        F.countDistinct(\"train_id\").alias(\"count_trains\"),\n",
    "        F.count(\"train_id\").alias(\"count_stops\"),\n",
    "        F.sum(F.col(\"3m_delay\").cast(\"long\")).alias(\"count_3m_delay\"),\n",
    "        F.sum(F.col(\"5m_delay\").cast(\"long\")).alias(\"count_5m_delay\"),\n",
    "        F.sum(F.col(\"10m_delay\").cast(\"long\")).alias(\"count_10m_delay\"),\n",
    "        F.first(\"stop_lat\").alias(\"stop_lat\"),\n",
    "        F.first(\"stop_lon\").alias(\"stop_lon\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stops:  2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Number of stops: \", data_stop_stat.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stops in (lat,long) dataset:  2961\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of stops in (lat,long) dataset: \", stops.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stops in final dataset:  2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Number of stops in final dataset: \", data_stop_stat.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_name</th>\n",
       "      <th>avg_arrival_delay</th>\n",
       "      <th>median_arrival_delay</th>\n",
       "      <th>count_trains</th>\n",
       "      <th>count_stops</th>\n",
       "      <th>count_3m_delay</th>\n",
       "      <th>count_5m_delay</th>\n",
       "      <th>count_10m_delay</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBASANTA</td>\n",
       "      <td>1.251249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>1401</td>\n",
       "      <td>205</td>\n",
       "      <td>131</td>\n",
       "      <td>79</td>\n",
       "      <td>40.128801</td>\n",
       "      <td>8.817733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBIATEGRASSO</td>\n",
       "      <td>2.978809</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57</td>\n",
       "      <td>3728</td>\n",
       "      <td>1105</td>\n",
       "      <td>596</td>\n",
       "      <td>209</td>\n",
       "      <td>45.400631</td>\n",
       "      <td>8.921305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACQUAVIVA</td>\n",
       "      <td>3.013732</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30</td>\n",
       "      <td>2039</td>\n",
       "      <td>721</td>\n",
       "      <td>327</td>\n",
       "      <td>61</td>\n",
       "      <td>37.570258</td>\n",
       "      <td>13.674927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACQUAVIVA DELLE FONTI</td>\n",
       "      <td>1.041216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2402</td>\n",
       "      <td>158</td>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>40.892806</td>\n",
       "      <td>16.839826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACQUEDOLCI-S.FRATELLO</td>\n",
       "      <td>0.272120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1198</td>\n",
       "      <td>93</td>\n",
       "      <td>57</td>\n",
       "      <td>22</td>\n",
       "      <td>38.058459</td>\n",
       "      <td>14.587597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CANDIOLO</td>\n",
       "      <td>4.380804</td>\n",
       "      <td>4.0</td>\n",
       "      <td>46</td>\n",
       "      <td>3532</td>\n",
       "      <td>1852</td>\n",
       "      <td>1119</td>\n",
       "      <td>123</td>\n",
       "      <td>44.961155</td>\n",
       "      <td>7.598973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>CANICATTI`</td>\n",
       "      <td>2.282486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>885</td>\n",
       "      <td>203</td>\n",
       "      <td>115</td>\n",
       "      <td>41</td>\n",
       "      <td>37.359879</td>\n",
       "      <td>13.855395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>CANISTRO</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>CANNETO SULL`OGLIO</td>\n",
       "      <td>6.860747</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1982</td>\n",
       "      <td>1365</td>\n",
       "      <td>939</td>\n",
       "      <td>288</td>\n",
       "      <td>45.150211</td>\n",
       "      <td>10.371470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CAPACI</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>38.171794</td>\n",
       "      <td>13.232398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                stop_name  avg_arrival_delay  median_arrival_delay  \\\n",
       "0               ABBASANTA           1.251249                   0.0   \n",
       "1           ABBIATEGRASSO           2.978809                   2.0   \n",
       "2               ACQUAVIVA           3.013732                   2.0   \n",
       "3   ACQUAVIVA DELLE FONTI           1.041216                   1.0   \n",
       "4   ACQUEDOLCI-S.FRATELLO           0.272120                   0.0   \n",
       "..                    ...                ...                   ...   \n",
       "95               CANDIOLO           4.380804                   4.0   \n",
       "96             CANICATTI`           2.282486                   1.0   \n",
       "97               CANISTRO           4.800000                   0.0   \n",
       "98     CANNETO SULL`OGLIO           6.860747                   5.0   \n",
       "99                 CAPACI           9.750000                  11.0   \n",
       "\n",
       "    count_trains  count_stops  count_3m_delay  count_5m_delay  \\\n",
       "0             29         1401             205             131   \n",
       "1             57         3728            1105             596   \n",
       "2             30         2039             721             327   \n",
       "3             36         2402             158              74   \n",
       "4             18         1198              93              57   \n",
       "..           ...          ...             ...             ...   \n",
       "95            46         3532            1852            1119   \n",
       "96            15          885             203             115   \n",
       "97             8           10               2               2   \n",
       "98            24         1982            1365             939   \n",
       "99             7            8               7               6   \n",
       "\n",
       "    count_10m_delay   stop_lat   stop_lon  \n",
       "0                79  40.128801   8.817733  \n",
       "1               209  45.400631   8.921305  \n",
       "2                61  37.570258  13.674927  \n",
       "3                35  40.892806  16.839826  \n",
       "4                22  38.058459  14.587597  \n",
       "..              ...        ...        ...  \n",
       "95              123  44.961155   7.598973  \n",
       "96               41  37.359879  13.855395  \n",
       "97                2        NaN        NaN  \n",
       "98              288  45.150211  10.371470  \n",
       "99                5  38.171794  13.232398  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stop_pandas = data_stop_stat.toPandas()\n",
    "data_stop_pandas.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "if SAVE_COMPUTATIONS:\n",
    "    data_stop_pandas.to_csv((\"dataset_generated/data_stop/data_stop.csv\"), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Statistics for each day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stop_stat = data_stop.groupBy(\"stop_name\", \"day_of_week\") \\\n",
    "    .agg(\n",
    "        F.avg(\"stop_arrival_delay\").alias(\"avg_arrival_delay\"),\n",
    "        F.percentile_approx(\"stop_arrival_delay\", 0.5).alias(\"median_arrival_delay\"),\n",
    "        F.countDistinct(\"train_id\").alias(\"count_trains\"),\n",
    "        F.count(\"train_id\").alias(\"count_stops\"),\n",
    "        F.sum(F.col(\"3m_delay\").cast(\"long\")).alias(\"count_3m_delay\"),\n",
    "        F.sum(F.col(\"5m_delay\").cast(\"long\")).alias(\"count_5m_delay\"),\n",
    "        F.sum(F.col(\"10m_delay\").cast(\"long\")).alias(\"count_10m_delay\"),\n",
    "        F.first(\"stop_lat\").alias(\"stop_lat\"),\n",
    "        F.first(\"stop_lon\").alias(\"stop_lon\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------------+--------------------+------------+-----------+--------------+--------------+---------------+---------+---------+\n",
      "|           stop_name|day_of_week|  avg_arrival_delay|median_arrival_delay|count_trains|count_stops|count_3m_delay|count_5m_delay|count_10m_delay| stop_lat| stop_lon|\n",
      "+--------------------+-----------+-------------------+--------------------+------------+-----------+--------------+--------------+---------------+---------+---------+\n",
      "|         ABANO TERME|        Mon| 2.1349862258953167|                 2.0|          28|        363|            76|            51|             18|45.355199|11.811533|\n",
      "|         ABANO TERME|        Tue| 1.3961218836565097|                 2.0|          28|        361|            75|            44|              6|45.355199|11.811533|\n",
      "|         ABANO TERME|        Wed| 1.6565096952908587|                 2.0|          28|        361|            82|            52|              8|45.355199|11.811533|\n",
      "|     ABBADIA LARIANA|        Tue|             1.0875|                 1.0|          25|        320|            47|            29|             13|45.895864| 9.335175|\n",
      "|           ABBASANTA|        Tue| 1.2995391705069124|                 0.0|          17|        217|            31|            22|             13|40.128801| 8.817733|\n",
      "|       ABBIATEGRASSO|        Sat| 1.6751054852320675|                 1.0|          40|        474|            89|            39|             10|45.400631| 8.921305|\n",
      "|       ABBIATEGRASSO|        Sun| 2.3852459016393444|                 1.0|          33|        366|            66|            37|             19|45.400631| 8.921305|\n",
      "|       ABBIATEGRASSO|        Tue|  4.085324232081911|                 2.0|          46|        586|           203|           129|             52|45.400631| 8.921305|\n",
      "|               ACATE|        Fri| 0.5909090909090909|                 0.0|           4|         44|             7|             4|              0|36.996592| 14.42545|\n",
      "|             ACCIANO|        Fri|             7.1875|                 7.0|           5|         48|            48|            35|              4|42.175994|13.711345|\n",
      "|              ACERRA|        Wed|   2.55977229601518|                 1.0|          43|        527|           129|            69|             25|40.939066|14.372243|\n",
      "|            ACIREALE|        Fri|  2.863128491620112|                 1.0|          79|        716|           148|           111|             59|37.600514|15.163697|\n",
      "|         ACQUAFREDDA|        Tue|               14.0|                 9.0|           3|          4|             3|             3|              1|40.035527|15.671846|\n",
      "|ACQUANEGRA CREMONESE|        Sat| 6.1525423728813555|                 3.0|           5|         59|            25|            16|              9|45.172102| 9.888456|\n",
      "|ACQUANEGRA CREMONESE|        Sun|  3.054054054054054|                 2.0|           4|         37|            13|             8|              1|45.172102| 9.888456|\n",
      "|          ACQUAPPESA|        Wed|               12.0|                12.0|           1|          1|             1|             1|              1| 39.48648|15.955992|\n",
      "|ACQUAVIVA DELLE F...|        Sat| 0.5972222222222222|                 0.0|          31|        360|            21|            10|              1|40.892806|16.839826|\n",
      "|ACQUAVIVA DELLE F...|        Thu| 1.6851851851851851|                 1.0|          31|        378|            29|            16|              8|40.892806|16.839826|\n",
      "|ACQUEDOLCI-S.FRAT...|        Sun|0.36923076923076925|                 0.0|           5|         65|             5|             3|              0|38.058459|14.587597|\n",
      "|ACQUEDOLCI-S.FRAT...|        Tue| 0.8238341968911918|                 0.0|          15|        193|            22|            11|              7|38.058459|14.587597|\n",
      "+--------------------+-----------+-------------------+--------------------+------------+-----------+--------------+--------------+---------------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_stop_stat.show()\n",
    "\n",
    "data_stop_stat_pandas = data_stop_stat.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file for each day of week with the statistics\n",
    "if SAVE_COMPUTATIONS:\n",
    "    for day in data_stop_stat_pandas[\"day_of_week\"].unique():\n",
    "        data_stop_stat_pandas[data_stop_stat_pandas[\"day_of_week\"] == day].to_csv((\"dataset_generated/data_stop/data_stop_{}.csv\".format(day)), index=False)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Statistics for each train type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stop_stat = data_stop.groupBy(\"stop_name\", \"train_class\") \\\n",
    "    .agg(\n",
    "        F.avg(\"stop_arrival_delay\").alias(\"avg_arrival_delay\"),\n",
    "        F.percentile_approx(\"stop_arrival_delay\", 0.5).alias(\"median_arrival_delay\"),\n",
    "        F.countDistinct(\"train_id\").alias(\"count_trains\"),\n",
    "        F.count(\"train_id\").alias(\"count_stops\"),\n",
    "        F.sum(F.col(\"3m_delay\").cast(\"long\")).alias(\"count_3m_delay\"),\n",
    "        F.sum(F.col(\"5m_delay\").cast(\"long\")).alias(\"count_5m_delay\"),\n",
    "        F.sum(F.col(\"10m_delay\").cast(\"long\")).alias(\"count_10m_delay\"),\n",
    "        F.first(\"stop_lat\").alias(\"stop_lat\"),\n",
    "        F.first(\"stop_lon\").alias(\"stop_lon\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------------+--------------------+------------+-----------+--------------+--------------+---------------+---------+---------+\n",
      "|           stop_name|train_class| avg_arrival_delay|median_arrival_delay|count_trains|count_stops|count_3m_delay|count_5m_delay|count_10m_delay| stop_lat| stop_lon|\n",
      "+--------------------+-----------+------------------+--------------------+------------+-----------+--------------+--------------+---------------+---------+---------+\n",
      "|           ABBASANTA|        REG| 1.251249107780157|                 0.0|          29|       1401|           205|           131|             79|40.128801| 8.817733|\n",
      "|ACQUAVIVA DELLE F...|        REG|1.0412156536219817|                 1.0|          36|       2402|           158|            74|             35|40.892806|16.839826|\n",
      "|         ACQUI TERME|        REG| 3.531089978054133|                 3.0|          41|       2734|           994|           453|            103| 44.67407| 8.474482|\n",
      "|AGROPOLI CASTELLA...|        ICN| 5.591549295774648|                 2.0|           2|         71|            27|            23|             13|40.351521|15.002053|\n",
      "|             AIRASCA|        REG| 4.418723404255319|                 4.0|          46|       3525|          2073|          1247|            134|44.928093| 7.483536|\n",
      "|              AIRUNO|        REG|3.0874976428436733|                 1.0|          69|       5303|          1339|           778|            275|45.754086| 9.422066|\n",
      "|                 ALA|        REG| 4.321287779237845|                 3.0|          69|       4566|          2119|          1360|            448|45.760087|10.996775|\n",
      "|                ALBA|        REG|0.5326170376055257|                 0.0|          18|       1303|           104|            34|             15|44.697713| 8.030629|\n",
      "|  ALBAIRATE VERMEZZO|        REG| 1.008749189889825|                 0.0|          95|       6172|          1067|           631|            279|     null|     null|\n",
      "|     ALBATE-TRECALLO|        REG| 2.538695917123705|                 2.0|          22|       1641|           396|           160|             19|45.777391| 9.095752|\n",
      "|            ALBISOLA|        REG|1.9523715803975594|                 1.0|         101|       5081|           798|           428|            139| 44.33469| 8.512092|\n",
      "|         ALESSANDRIA|        REG|1.1352555701179554|                 1.0|         121|       7630|          1794|          1020|            287|44.909091| 8.606498|\n",
      "|      ALICE BELCOLLE|        REG|0.9135538954108858|                 0.0|          16|        937|            36|            18|              7|44.722636| 8.440076|\n",
      "|          ALI` TERME|        REG| 2.331540013449899|                 1.0|          51|       2974|           721|           458|            162|38.013952|15.435184|\n",
      "|              ALTARE|        REG|1.3159851301115242|                 0.0|          11|        807|            77|            61|             32|44.336169| 8.332753|\n",
      "|   AMOROSI MELIZZANO|         IC|              10.5|                 7.0|           1|          2|             2|             2|              1|41.173509|14.470759|\n",
      "|              ANCONA|        REG|0.9907662400777579|                -1.0|         104|       6173|           956|           535|            265|43.607734|13.497665|\n",
      "|              ANDORA|        REG|2.5813076278290024|                 1.0|          41|       2386|           749|           491|            124|     null|     null|\n",
      "|ANTRODOCO BORGO V...|        REG| 2.422520107238606|                 2.0|          32|       1865|           486|           206|             64|42.415393|13.076193|\n",
      "|             APPIANO|        REG| 2.130678693213068|                 1.0|         152|       9091|          1414|           496|            110|41.909342| 12.43838|\n",
      "+--------------------+-----------+------------------+--------------------+------------+-----------+--------------+--------------+---------------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_stop_stat.show()\n",
    "\n",
    "data_stop_stat_pandas = data_stop_stat.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file for each day of week with the statistics\n",
    "if SAVE_COMPUTATIONS:\n",
    "    for train_class in data_stop_stat_pandas[\"train_class\"].unique():\n",
    "        data_stop_stat_pandas[data_stop_stat_pandas[\"train_class\"] == train_class].to_csv((\"dataset_generated/data_stop/data_stop_class_{}.csv\".format(train_class)), index=False)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d. Statistics for each week day and train type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stop_stat = data_stop.groupBy(\"stop_name\", \"train_class\", \"day_of_week\") \\\n",
    "    .agg(\n",
    "        F.avg(\"stop_arrival_delay\").alias(\"avg_arrival_delay\"),\n",
    "        F.percentile_approx(\"stop_arrival_delay\", 0.5).alias(\"median_arrival_delay\"),\n",
    "        F.countDistinct(\"train_id\").alias(\"count_trains\"),\n",
    "        F.count(\"train_id\").alias(\"count_stops\"),\n",
    "        F.sum(F.col(\"3m_delay\").cast(\"long\")).alias(\"count_3m_delay\"),\n",
    "        F.sum(F.col(\"5m_delay\").cast(\"long\")).alias(\"count_5m_delay\"),\n",
    "        F.sum(F.col(\"10m_delay\").cast(\"long\")).alias(\"count_10m_delay\"),\n",
    "        F.first(\"stop_lat\").alias(\"stop_lat\"),\n",
    "        F.first(\"stop_lon\").alias(\"stop_lon\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_stop_stat_pandas = data_stop_stat.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each combination of weekday and train_class, create a file with the statistics\n",
    "if SAVE_COMPUTATIONS:\n",
    "    for day in data_stop_stat_pandas[\"day_of_week\"].unique():\n",
    "        for train_class in data_stop_stat_pandas[\"train_class\"].unique():\n",
    "            data_stop_stat_pandas[(data_stop_stat_pandas[\"day_of_week\"] == day) & (data_stop_stat_pandas[\"train_class\"] == train_class)].to_csv((\"dataset_generated/data_stop/data_stop_mix_{}_{}.csv\".format(day, train_class)), index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train statistics\n",
    "For each train, the goal is to store the following information:\n",
    "1. Ordered list of the stations it stopped at\n",
    "2. For each destination: \n",
    "    1. Average arrival delay\n",
    "    2. Median arrival delay\n",
    "    3. % of trains with delay > 3\n",
    "    4. % of trains with delay > 5\n",
    "    5. % of trains with delay > 10\n",
    "    6. Number of days it stopped at the destination\n",
    "\n",
    "To avoid keeping statistics for temporary stops and trains, we remove: \n",
    "- Trains that appeared in the dataset only <10  distinct times\n",
    "- Stops for a train, that appeared less than 20% of the dates that the train appeared in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we add coordinates to each stop, so that we can drop stops for which we don't have the coordinates\n",
    "df_trains = df.join(stops, on=\"stop_name\", how=\"inner\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. For each train, we obtain the statistics of each of its stops, removing the stops that appear less than 20% of the dates that the train appeared in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_arrival_stop_name', 'train_class', 'train_cn', 'train_dl', 'train_number', 'train_arrival_time', 'oae', 'train_oaz', 'train_od', 'train_oo', 'train_departure_time', 'train_ope', 'train_opz', 'train_departure_stop_name', 'train_pr', 'train_arrival_delay', 'train_departure_delay', 'sea', 'train_sep', 'train_sub', 'day', 'month', 'year', 'date', 'stop_name', 'stop_arrival_time', 'stop_departure_time', 'stop_arrival_delay', 'stop_departure_delay']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, we have to keep in mind that the same train number can refer to multiple trains, so we also have to group by the destination stop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 95:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|train_arrival_stop_name|\n",
      "+-----------------------+\n",
      "|           ROMA TERMINI|\n",
      "|         COMO NORD LAGO|\n",
      "+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# this shows that there's multiple trains with the same number\n",
    "df \\\n",
    "    .filter((F.col(\"train_class\") == \"REG\") & (F.col(\"train_number\") == \"4113\"))\\\n",
    "    .select(\"train_arrival_stop_name\")\\\n",
    "    .distinct()\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/21 10:56:32 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------+-----------+--------+--------+------------+------------------+----+----------+--------+--------+--------------------+---------+----------+-------------------------+--------+-------------------+---------------------+----+---------+---------+---+-----+----+----------+-----------------+-------------------+------------------+--------------------+-------+----------------+---------+---------+--------------+-----+---------+\n",
      "|           stop_name|train_arrival_stop_name|train_class|train_cn|train_dl|train_number|train_arrival_time| oae| train_oaz|train_od|train_oo|train_departure_time|train_ope| train_opz|train_departure_stop_name|train_pr|train_arrival_delay|train_departure_delay| sea|train_sep|train_sub|day|month|year|      date|stop_arrival_time|stop_departure_time|stop_arrival_delay|stop_departure_delay|stop_id| stop_name_short| stop_lat| stop_lon|stop_id_region|delay|stop_time|\n",
      "+--------------------+-----------------------+-----------+--------+--------+------------+------------------+----+----------+--------+--------+--------------------+---------+----------+-------------------------+--------+-------------------+---------------------+----+---------+---------+---+-----+----+----------+-----------------+-------------------+------------------+--------------------+-------+----------------+---------+---------+--------------+-----+---------+\n",
      "|          CISTERNINO|                  LECCE|        REG|    null|    null|       34445|        1674864180|null|1674864180|    null|    null|          1674857400|     null|1674857400|            BARI CENTRALE|    null|                  2|                    3|null|     null|     null| 28|   01|2023|2023-01-28|       1674860400|         1674860460|              n.d.|                   5| S11131|      Cisternino|40.816652|17.456899|          16.0| n.d.|    00:00|\n",
      "|MILANO GRECO PIRELLI|   MILANO PORTA GARI...|        REG|    null|    null|       33067|        1679955420|null|1679955420|    null|    null|          1679951160|     null|1679951160|                    LECCO|    null|                 -2|                    1|null|     null|     null| 28|   03|2023|2023-03-28|       1679954400|         1679954460|                -1|                   0| S01326|MI Greco Pirelli| 45.51272| 9.214456|           1.0|   -1|    00:00|\n",
      "|MILANO GRECO PIRELLI|   MILANO PORTA GARI...|        REG|    null|    null|       33067|        1679008620|null|1679008620|    null|    null|          1679004360|     null|1679004360|                    LECCO|    null|                 -3|                    0|null|     null|     null| 17|   03|2023|2023-03-17|       1679007600|         1679007660|                -1|                   0| S01326|MI Greco Pirelli| 45.51272| 9.214456|           1.0|   -1|    00:00|\n",
      "|          CISTERNINO|                  LECCE|        REG|    null|    null|       34445|        1678320180|null|1678320180|    null|    null|          1678313400|     null|1678313400|            BARI CENTRALE|    null|                 10|                    4|null|     null|     null| 09|   03|2023|2023-03-09|       1678316400|         1678316460|              n.d.|                  12| S11131|      Cisternino|40.816652|17.456899|          16.0| n.d.|    00:00|\n",
      "|             VIGNATE|                BERGAMO|        REG|    null|    null|        2247|        1676418600|null|1676418600|    null|    null|          1676414400|     null|1676414400|          MILANO CENTRALE|    null|                  1|                    1|null|     null|     null| 15|   02|2023|2023-02-15|       1676415600|         1676415660|              n.d.|                   1| S01704|         Vignate|45.493946| 9.374083|           1.0| n.d.|    00:00|\n",
      "|           MACCARESE|          CIVITAVECCHIA|        REG|    null|    null|       12554|        1678319040|null|1678319040|    null|    null|          1678314420|     null|1678314420|             ROMA TERMINI|    null|                  1|                    0|null|     null|     null| 09|   03|2023|2023-03-09|       1678316400|         1678316460|                 1|                   2| S08020|       Maccarese|41.879372| 12.23695|           5.0|    1|    00:00|\n",
      "|          CISTERNINO|                  LECCE|        REG|    null|    null|       34445|        1675123380|null|1675123380|    null|    null|          1675116600|     null|1675116600|            BARI CENTRALE|    null|                 -1|                    3|null|     null|     null| 31|   01|2023|2023-01-31|       1675119600|         1675119660|              n.d.|                   2| S11131|      Cisternino|40.816652|17.456899|          16.0| n.d.|    00:00|\n",
      "|           MACCARESE|          CIVITAVECCHIA|        REG|    null|    null|       12554|        1679957040|null|1679957040|    null|    null|          1679952420|     null|1679952420|             ROMA TERMINI|    null|                  1|                    0|null|     null|     null| 28|   03|2023|2023-03-28|       1679954400|         1679954460|                 4|                   5| S08020|       Maccarese|41.879372| 12.23695|           5.0|    4|    00:00|\n",
      "|MILANO GRECO PIRELLI|   MILANO PORTA GARI...|        REG|    null|    null|       24889|        1674860880|null|1674860880|    null|    null|          1674857160|     null|1674857160|                    LECCO|    null|                 -2|                    0|null|     null|     null| 28|   01|2023|2023-01-28|       1674860400|         1674860460|                -2|                   1| S01326|MI Greco Pirelli| 45.51272| 9.214456|           1.0|   -2|    00:00|\n",
      "|              VARESE|                 STABIO|        REG|    null|    null|       25592|        1678317720|null|1678317720|    null|    null|          1678313940|     null|1678313940|     MALPENSA AEROPORT...|    null|                 -1|                    1|null|     null|     null| 09|   03|2023|2023-03-09|       1678316400|         1678316760|                 1|                   1| S01205|          Varese|45.816201| 8.833089|           1.0|    1|    00:00|\n",
      "+--------------------+-----------------------+-----------+--------+--------+------------+------------------+----+----------+--------+--------+--------------------+---------+----------+-------------------------+--------+-------------------+---------------------+----+---------+---------+---+-----+----+----------+-----------------+-------------------+------------------+--------------------+-------+----------------+---------+---------+--------------+-----+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first we create a new column with the delay in minutes. For all stops this has to be the arrival_delay apart for the first stop of each train, for which it has to be the departure_delay\n",
    "df_trains1 = df_trains.withColumn(\"delay\", F.when(F.col(\"stop_arrival_delay\") == \"N\", F.col(\"stop_departure_delay\")).otherwise(F.col(\"stop_arrival_delay\")))\n",
    "\n",
    "# second, add a column \"stop_arrival_time\", which is the arrival time at the stop, in the format \"HH:MM\"\n",
    "# if the stop is the first stop of the train, then the stop_arrival_time is the departure time of the train\n",
    "\n",
    "df_trains1 = df_trains1\\\n",
    "    .withColumn(\"stop_time\", F.when(F.col(\"stop_arrival_time\") == 0, F.col(\"stop_departure_time\")).otherwise(F.col(\"stop_arrival_time\"))) \\\n",
    "    .withColumn(\"stop_time\", F.date_format(F.col(\"stop_time\").cast(\"timestamp\"), \"HH:mm\"))\n",
    "\n",
    "    \n",
    "\n",
    "df_trains1.orderBy(\"stop_time\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----------------------+-----------+------------+----------+-------+---------+--------------+---------------+---------+---------+--------------+--------+--------+---------+-----+\n",
      "|train_departure_stop_name|train_arrival_stop_name|train_class|train_number|      date|stop_id|stop_time|     stop_name|stop_name_short| stop_lat| stop_lon|stop_id_region|3m_delay|5m_delay|10m_delay|delay|\n",
      "+-------------------------+-----------------------+-----------+------------+----------+-------+---------+--------------+---------------+---------+---------+--------------+--------+--------+---------+-----+\n",
      "|           FIRENZE S.M.N.|           ROMA TERMINI|        REG|        4113|2023-02-06| S06421|    21:14|FIRENZE S.M.N.| Firenze S.M.N.|43.776893|11.247373|          13.0|       1|       1|        1| 19.0|\n",
      "+-------------------------+-----------------------+-----------+------------+----------+-------+---------+--------------+---------------+---------+---------+--------------+--------+--------+---------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert the delay to double and add a counter if the train was 3m, 5m, 10m late\n",
    "# add a column with the number of distinct dates for each train\n",
    "# remove the column if the delay cannot be casted to double\n",
    "df_trains2 = df_trains1 \\\n",
    "    .withColumn(\"delay\", F.col(\"delay\").cast(\"double\")) \\\n",
    "    .filter(F.col(\"delay\").isNotNull()) \\\n",
    "    .withColumn(\"3m_delay\", F.when(F.col(\"delay\") >= 3, 1).otherwise(0)) \\\n",
    "    .withColumn(\"5m_delay\", F.when(F.col(\"delay\") >= 5, 1).otherwise(0)) \\\n",
    "    .withColumn(\"10m_delay\", F.when(F.col(\"delay\") >= 10, 1).otherwise(0))\\\n",
    "    .select(\"train_departure_stop_name\", \"train_arrival_stop_name\", \"train_class\", \"train_number\", \"date\", \"stop_id\", \"stop_time\", \"stop_name\", \"stop_name_short\", \"stop_lat\", \"stop_lon\", \"stop_id_region\", \"3m_delay\", \"5m_delay\", \"10m_delay\", \"delay\")\n",
    "\n",
    "df_trains2.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For each train, we obtain the statistics of each of its stops, removing the stops that appear less than 20% of the dates that the train appeared in the dataset\n",
    "# add the stop incremental number\n",
    "df_trains_stat1 = df_trains2.groupBy(\"train_class\", \"train_number\", \"train_departure_stop_name\", \"train_arrival_stop_name\", \"stop_name\") \\\n",
    "    .agg(\n",
    "        F.avg(\"delay\").alias(\"avg_arrival_delay\"),\n",
    "        F.percentile_approx(\"delay\", 0.5).alias(\"median_arrival_delay\"),\n",
    "        F.countDistinct(\"date\").alias(\"count_dates_stop\"),\n",
    "        F.min(\"date\").alias(\"first_date\"),\n",
    "        F.max(\"date\").alias(\"last_date\"),\n",
    "        F.sum(F.col(\"3m_delay\").cast(\"long\")).alias(\"count_3m_delay\"),\n",
    "        F.sum(F.col(\"5m_delay\").cast(\"long\")).alias(\"count_5m_delay\"),\n",
    "        F.sum(F.col(\"10m_delay\").cast(\"long\")).alias(\"count_10m_delay\"),\n",
    "        F.first(\"stop_lat\").alias(\"stop_lat\"),\n",
    "        F.first(\"stop_lon\").alias(\"stop_lon\"),\n",
    "        F.mode(\"stop_time\").alias(\"stop_time\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts how many distinct dates a train apparead in the dataset\n",
    "# and filter out trains that didn't appear at least 4 times a month (12 times in total)\n",
    "MIN_THRESHOLD_TRAIN = 12\n",
    "\n",
    "df_trains_counts = df_trains2.groupBy(\"train_class\", \"train_number\", \"train_departure_stop_name\", \"train_arrival_stop_name\") \\\n",
    "    .agg(\n",
    "        F.countDistinct(\"date\").alias(\"count_dates_train\")\n",
    "    ) \\\n",
    "    .filter(F.col(\"count_dates_train\") >= MIN_THRESHOLD_TRAIN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to store the data we create a mapper from a (train_class, train_number, train_arrival_stop_name) to an id, and we store the information of that train on a file with the name of the id. To do that, we add a column which is a monotonic increasing id, and we use that as the id of that train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trains_counts = df_trains_counts \\\n",
    "    .withColumn(\"train_id\", F.monotonically_increasing_id()) \\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two datasets and filter out stations that appear in less than 20% of the dates\n",
    "df_trains_stat2 = df_trains_stat1.join(df_trains_counts, on=[\"train_class\", \"train_number\", \"train_arrival_stop_name\", \"train_departure_stop_name\"], how=\"inner\") \\\n",
    "    .filter(F.col(\"count_dates_stop\") >= F.col(\"count_dates_train\") * 0.2) \\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-----------------------+-------------------------+---------------+------------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+--------+\n",
      "|train_class|train_number|train_arrival_stop_name|train_departure_stop_name|      stop_name| avg_arrival_delay|median_arrival_delay|count_dates_stop|first_date| last_date|count_3m_delay|count_5m_delay|count_10m_delay| stop_lat| stop_lon|stop_time|count_dates_train|train_id|\n",
      "+-----------+------------+-----------------------+-------------------------+---------------+------------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+--------+\n",
      "|         IC|         700|           ROMA TERMINI|              BATTIPAGLIA|         LATINA| 9.083333333333334|                 4.0|              12|2023-01-21|2023-02-01|             7|             5|              2|41.538372|12.945888|    13:58|               12|      35|\n",
      "|         IC|         700|           ROMA TERMINI|              BATTIPAGLIA|NAPOLI CENTRALE|12.583333333333334|                 5.0|              12|2023-01-21|2023-02-01|             9|             7|              4|40.852933|14.272908|    12:18|               12|      35|\n",
      "|         IC|         700|           ROMA TERMINI|              BATTIPAGLIA|    BATTIPAGLIA|1.6666666666666667|                 1.0|              12|2023-01-21|2023-02-01|             3|             0|              0|40.605789| 14.98324|    11:27|               12|      35|\n",
      "|         IC|         700|           ROMA TERMINI|              BATTIPAGLIA|        SALERNO| 4.083333333333333|                 2.0|              12|2023-01-21|2023-02-01|             6|             3|              1|40.675137|14.772822|    11:38|               12|      35|\n",
      "|         IC|         700|           ROMA TERMINI|              BATTIPAGLIA|   ROMA TERMINI| 9.833333333333334|                 0.0|              12|2023-01-21|2023-02-01|             4|             2|              2|41.900636|12.502026|    14:34|               12|      35|\n",
      "|         IC|         700|           ROMA TERMINI|              BATTIPAGLIA|   FORMIA-GAETA|13.916666666666666|                 8.0|              12|2023-01-21|2023-02-01|            12|             9|              3|41.258773|13.605996|    13:20|               12|      35|\n",
      "|         IC|         700|           ROMA TERMINI|              BATTIPAGLIA|         AVERSA|             10.25|                 3.0|              12|2023-01-21|2023-02-01|             7|             5|              3|40.973323|14.218578|    12:47|               12|      35|\n",
      "|        REG|       10004|                CREMONA|                  MANTOVA|        PIADENA| 5.213333333333333|                 5.0|              75|2023-01-02|2023-03-31|            53|            39|             10|45.127608|10.369962|    08:30|               75|      20|\n",
      "|        REG|       10004|                CREMONA|                  MANTOVA|  CASTELLUCCHIO|2.7733333333333334|                 2.0|              75|2023-01-02|2023-03-31|            37|             5|              1|45.144293| 10.64749|    08:03|               75|      20|\n",
      "|        REG|       10004|                CREMONA|                  MANTOVA|        CREMONA| 5.733333333333333|                 5.0|              75|2023-01-02|2023-03-31|            54|            39|             15|45.143215|10.017951|    08:49|               75|      20|\n",
      "+-----------+------------+-----------------------+-------------------------+---------------+------------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_trains_stat2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 123:==================================================>  (189 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-----------------------+-------------------------+--------------------+--------------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+--------+-----------+\n",
      "|train_class|train_number|train_arrival_stop_name|train_departure_stop_name|           stop_name|   avg_arrival_delay|median_arrival_delay|count_dates_stop|first_date| last_date|count_3m_delay|count_5m_delay|count_10m_delay| stop_lat| stop_lon|stop_time|count_dates_train|train_id|stop_number|\n",
      "+-----------+------------+-----------------------+-------------------------+--------------------+--------------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+--------+-----------+\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|              SAVONA|  2.5238095238095237|                 2.0|              63|2023-01-02|2023-03-31|            13|             4|              1|44.306892| 8.470259|    06:28|               63|       0|          1|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|       GENOVA VOLTRI| -1.3650793650793651|                -3.0|              63|2023-01-02|2023-03-31|             9|             5|              0|44.428467| 8.758163|    06:48|               63|       0|          2|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|GENOVA SESTRI PON...|  0.5873015873015873|                 0.0|              63|2023-01-02|2023-03-31|             5|             2|              0|44.422374| 8.847707|    07:02|               63|       0|          3|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|GENOVA SAMPIERDARENA|  -2.238095238095238|                -3.0|              63|2023-01-02|2023-03-31|             2|             0|              0|44.413102| 8.887271|    07:13|               63|       0|          4|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|   GENOVA P.PRINCIPE|  1.3650793650793651|                 1.0|              63|2023-01-02|2023-03-31|             7|             6|              1|44.417784|   8.9207|    07:20|               63|       0|          5|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|     GENOVA BRIGNOLE| 0.38095238095238093|                 1.0|              63|2023-01-02|2023-03-31|             9|             2|              0|44.407213| 8.947553|    07:31|               63|       0|          6|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|GENOVA QUARTO DEI...|  1.7777777777777777|                 1.0|              63|2023-01-02|2023-03-31|            10|             5|              0|44.388607|  8.99597|    07:41|               63|       0|          7|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|        GENOVA NERVI|  2.0952380952380953|                 1.0|              63|2023-01-02|2023-03-31|            19|             5|              0|44.381271| 9.039895|    07:48|               63|       0|          8|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|               RECCO|-0.06349206349206349|                -1.0|              63|2023-01-02|2023-03-31|             8|             3|              0|44.361215| 9.146788|    08:08|               63|       0|          9|\n",
      "|        REG|         876|            M N CADORNA|                  SARONNO|             SARONNO|                 0.0|                 0.0|              89|2023-01-01|2023-03-31|             0|             0|              0|45.625309| 9.030839|    19:53|               89|       1|          1|\n",
      "|        REG|         876|            M N CADORNA|                  SARONNO|         SARONNO SUD|                 0.0|                 0.0|              89|2023-01-01|2023-03-31|             0|             0|              0|     null|     null|    19:56|               89|       1|          2|\n",
      "|        REG|         876|            M N CADORNA|                  SARONNO|              CESATE|                 0.0|                 0.0|              89|2023-01-01|2023-03-31|             0|             0|              0|     null|     null|    20:00|               89|       1|          3|\n",
      "|        REG|         876|            M N CADORNA|                  SARONNO|        BOLLATE NORD|                 0.0|                 0.0|              89|2023-01-01|2023-03-31|             0|             0|              0|     null|     null|    20:07|               89|       1|          4|\n",
      "|        REG|         876|            M N CADORNA|                  SARONNO|      BOLLATE CENTRO|                 0.0|                 0.0|              89|2023-01-01|2023-03-31|             0|             0|              0|     null|     null|    20:09|               89|       1|          5|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|MILANO PORTA GARI...|  1.8153846153846154|                 1.0|              65|2023-01-02|2023-03-31|             9|             2|              2|45.484917| 9.187683|    21:46|               65|       2|          1|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|    RHO FIERA MILANO|  0.3230769230769231|                -1.0|              65|2023-01-02|2023-03-31|             6|             2|              1|45.521157| 9.088595|    21:56|               65|       2|          2|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|       BUSTO ARSIZIO|  -3.830769230769231|                -4.0|              65|2023-01-02|2023-03-31|             1|             1|              1|45.616164| 8.865031|    22:17|               65|       2|          3|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|           GALLARATE|             1.03125|                 1.0|              64|2023-01-02|2023-03-31|             6|             1|              1|45.659828| 8.798243|    22:23|               65|       2|          4|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|   CASORATE SEMPIONE|  1.6307692307692307|                 1.0|              65|2023-01-02|2023-03-31|             9|             2|              1|45.675075| 8.743954|    22:28|               65|       2|          5|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|      SOMMA LOMBARDO|  0.3076923076923077|                 0.0|              65|2023-01-02|2023-03-31|             7|             2|              1|45.686423| 8.712991|    22:32|               65|       2|          6|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|            VERGIATE| -0.1076923076923077|                -1.0|              65|2023-01-02|2023-03-31|             4|             1|              1|45.717119| 8.693187|    22:36|               65|       2|          7|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|       SESTO CALENDE|-0.13846153846153847|                -1.0|              65|2023-01-02|2023-03-31|             3|             3|              1|45.726241| 8.628135|    22:42|               65|       2|          8|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|         DORMELLETTO| 0.23076923076923078|                 0.0|              65|2023-01-02|2023-03-31|             6|             3|              1|  45.7233| 8.581906|    22:47|               65|       2|          9|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|               ARONA|-0.13846153846153847|                -1.0|              65|2023-01-02|2023-03-31|             5|             4|              1|45.755392| 8.559075|    22:54|               65|       2|         10|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|    PALERMO CENTRALE|            0.421875|                 0.0|              64|2023-01-02|2023-03-31|             1|             0|              0|38.109187|13.367515|    20:33|               64|       3|          1|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|     TERMINI IMERESE|              -2.625|                -3.0|              64|2023-01-02|2023-03-31|             0|             0|              0|37.980132|13.703631|    20:57|               64|       3|          2|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|             CEFALU`|           -0.859375|                -1.0|              64|2023-01-02|2023-03-31|             2|             1|              0| 38.03285|14.019526|    21:15|               64|       3|          3|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|SANTO STEFANO DI ...|           -2.171875|                -3.0|              64|2023-01-02|2023-03-31|             3|             1|              1| 38.01778| 14.35104|    21:42|               64|       3|          4|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|          S.AGATA M.|            -0.84375|                -2.0|              64|2023-01-02|2023-03-31|             9|             4|              2|38.073554|14.640622|    22:05|               64|       3|          5|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE| CAPO D`ORLANDO-NASO|            1.296875|                 1.0|              64|2023-01-02|2023-03-31|             9|             5|              2|38.157941|14.744844|    22:20|               64|       3|          6|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|PATTI-SAN PIERO P...|  2.4761904761904763|                 1.0|              63|2023-01-02|2023-03-31|            19|             7|              4|38.146905|14.975331|    22:37|               64|       3|          7|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|          BARCELLONA|  1.8548387096774193|                 1.0|              62|2023-01-02|2023-03-31|            14|             9|              3| 38.14918|15.212499|    22:49|               64|       3|          8|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|             MILAZZO|   2.161290322580645|                 1.0|              62|2023-01-02|2023-03-31|            18|            10|              2| 38.21195|15.244203|    22:55|               64|       3|          9|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|    MESSINA CENTRALE|           -0.140625|                 0.0|              64|2023-01-02|2023-03-31|            13|             8|              1|38.184975|15.561278|    23:20|               64|       3|         10|\n",
      "|        REG|       22402|                  CARPI|                   MODENA|              MODENA|  1.7916666666666667|                 2.0|              72|2023-01-02|2023-03-31|             8|             0|              0|44.654461|10.930373|    07:34|               72|       4|          1|\n",
      "|        REG|       22402|                  CARPI|                   MODENA|       QUATTRO VILLE| 0.08333333333333333|                 0.0|              72|2023-01-02|2023-03-31|             3|             0|              0|     null|     null|    07:40|               72|       4|          2|\n",
      "|        REG|       22402|                  CARPI|                   MODENA|               CARPI| 0.09722222222222222|                 0.0|              72|2023-01-02|2023-03-31|             5|             2|              0|44.782919|10.891952|    07:50|               72|       4|          3|\n",
      "|        REG|        5010|   MERCATO SAN SEVERINO|                  SALERNO|             SALERNO|  1.8426966292134832|                 1.0|              89|2023-01-01|2023-03-31|            22|             5|              2|40.675137|14.772822|    07:33|               89|       5|          1|\n",
      "|        REG|        5010|   MERCATO SAN SEVERINO|                  SALERNO|              FRATTE|  2.5730337078651684|                 2.0|              89|2023-01-01|2023-03-31|            39|            10|              1|40.705637|14.778362|    07:43|               89|       5|          2|\n",
      "|        REG|        5010|   MERCATO SAN SEVERINO|                  SALERNO|          PELLEZZANO|  3.5168539325842696|                 3.0|              89|2023-01-01|2023-03-31|            51|            19|              4|40.719928|14.777354|    07:51|               89|       5|          3|\n",
      "|        REG|        5010|   MERCATO SAN SEVERINO|                  SALERNO|           BARONISSI|   2.101123595505618|                 2.0|              89|2023-01-01|2023-03-31|            31|            12|              2|40.743779| 14.77224|    08:00|               89|       5|          4|\n",
      "|        REG|        5010|   MERCATO SAN SEVERINO|                  SALERNO|            FISCIANO|  1.4943820224719102|                 1.0|              89|2023-01-01|2023-03-31|            21|            10|              2|40.759095| 14.77486|    08:06|               89|       5|          5|\n",
      "|        REG|        5010|   MERCATO SAN SEVERINO|                  SALERNO|MERCATO SAN SEVERINO|  2.2247191011235956|                 2.0|              89|2023-01-01|2023-03-31|            31|            11|              2|40.783095|14.759749|    08:12|               89|       5|          6|\n",
      "|        REG|       21813|       PALERMO CENTRALE|          TERMINI IMERESE|     TERMINI IMERESE|  0.9733333333333334|                 1.0|              75|2023-01-02|2023-03-31|             5|             1|              0|37.980132|13.703631|    10:34|               75|       6|          1|\n",
      "|        REG|       21813|       PALERMO CENTRALE|          TERMINI IMERESE|        ALTAVILLA M.|               -0.76|                -1.0|              75|2023-01-02|2023-03-31|             1|             0|              0|38.048392|13.554421|    10:50|               75|       6|          2|\n",
      "|        REG|       21813|       PALERMO CENTRALE|          TERMINI IMERESE|            BAGHERIA|                1.32|                 1.0|              75|2023-01-02|2023-03-31|            11|             2|              0|38.089905|13.507215|    11:00|               75|       6|          3|\n",
      "|        REG|       21813|       PALERMO CENTRALE|          TERMINI IMERESE|  PALERMO BRANCACCIO|                1.12|                 1.0|              75|2023-01-02|2023-03-31|            11|             2|              0|38.093141|13.392508|    11:12|               75|       6|          4|\n",
      "|        REG|       21813|       PALERMO CENTRALE|          TERMINI IMERESE|    PALERMO CENTRALE|  1.1866666666666668|                 1.0|              75|2023-01-02|2023-03-31|             9|             2|              0|38.109187|13.367515|    11:17|               75|       6|          5|\n",
      "|        REG|       19874|                  MELFI|         POTENZA CENTRALE|    POTENZA CENTRALE|  2.3421052631578947|                 1.0|              76|2023-01-02|2023-03-31|             5|             3|              3|40.629469|15.806808|    07:15|               76|       7|          1|\n",
      "|        REG|       19874|                  MELFI|         POTENZA CENTRALE|   POTENZA SUPERIORE| 0.14473684210526316|                -1.0|              76|2023-01-02|2023-03-31|             5|             3|              3| 40.64586|15.800966|    07:21|               76|       7|          2|\n",
      "+-----------+------------+-----------------------+-------------------------+--------------------+--------------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+--------+-----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "# add the stop incremental number\n",
    "df_trains_stat3 = df_trains_stat2 \\\n",
    "    .withColumn(\"stop_number\", F.row_number().over(Window.partitionBy(\"train_id\").orderBy(\"stop_time\"))) \\\n",
    "    .sort(\"train_id\", \"stop_number\") \\\n",
    "    .cache()\n",
    "\n",
    "\n",
    "df_trains_stat3.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# now we store df_trains_stat2 in a csv file, partitioned by the column \"train_id\". \n",
    "# Each \"train_id\" should have a single file, and each file should contain the statistics of all the stops of the train\n",
    "\n",
    "# remove folder if it already exists\n",
    "\n",
    "if SAVE_COMPUTATIONS : \n",
    "    import shutil\n",
    "    shutil.rmtree(\"dataset_generated/data_train_stat\")\n",
    "\n",
    "\n",
    "    df_trains_stat3 \\\n",
    "        .repartition(\"train_id\") \\\n",
    "        .write \\\n",
    "        .partitionBy(\"train_id\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(\"dataset_generated/data_train_stat/data_train_stat.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read from file\n",
    "df_trains_stat3 = spark.read.option(\"header\", \"true\").csv(\"dataset_generated/data_train_stat/data_train_stat.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to elaborate some general stastistics about a train, and store a dataset which is an index of the train ids, and the statistics of that train.\n",
    "\n",
    "The aggregated statistics that we want to store are: \n",
    "1. Average arrival delay at each destination\n",
    "2. Median arrival delay at each destination\n",
    "3. % of trains with delay > 3 at each destination\n",
    "4. % of trains with delay > 5 at each destination\n",
    "5. % of trains with delay > 10 at each destination\n",
    "6. Number of days the train ran\n",
    "7. Number of stops of the train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trains_stat3.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we want to elaborate some general stastistics about a train, and store a dataset which is an index of the train ids, and the statistics of that train.\n",
    "\n",
    "# The aggregated statistics that we want to store are: \n",
    "# 1. Average arrival delay at each destination\n",
    "# 2. Median arrival delay at each destination\n",
    "# 3. % of trains with delay > 3 at each destination\n",
    "# 4. % of trains with delay > 5 at each destination\n",
    "# 5. % of trains with delay > 10 at each destination\n",
    "# 6. Number of days the train ran\n",
    "# 7. Number of stops of the train\n",
    "\n",
    "\n",
    "df_trains_stat4 = df_trains_stat3 \\\n",
    "    .groupBy(\"train_id\", \"train_class\", \"train_number\", \"train_departure_stop_name\", \"train_arrival_stop_name\") \\\n",
    "    .agg(\n",
    "        F.avg(\"avg_arrival_delay\").alias(\"avg_arrival_delay\"),\n",
    "        F.avg(\"median_arrival_delay\").alias(\"median_arrival_delay\"),\n",
    "        (F.avg(\"count_3m_delay\") / F.first(\"count_dates_train\")).alias(\"perc_3m_delay\"),\n",
    "        (F.avg(\"count_5m_delay\") / F.first(\"count_dates_train\")).alias(\"perc_5m_delay\"),\n",
    "        (F.avg(\"count_10m_delay\") / F.first(\"count_dates_train\")).alias(\"perc_10m_delay\"),\n",
    "        F.first(\"count_dates_train\").alias(\"count_dates_train\"),\n",
    "        F.countDistinct(\"stop_name\").alias(\"count_stops_train\"),\n",
    "        F.first(\"first_date\").alias(\"first_date\"),\n",
    "        F.first(\"last_date\").alias(\"last_date\"),\n",
    "        F.min(\"stop_time\").alias(\"departure_time\"),\n",
    "        F.max(\"stop_time\").alias(\"arrival_time\"),\n",
    "    ) \\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_trains_stat4_pandas = df_trains_stat4.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>train_class</th>\n",
       "      <th>train_number</th>\n",
       "      <th>train_departure_stop_name</th>\n",
       "      <th>train_arrival_stop_name</th>\n",
       "      <th>avg_arrival_delay</th>\n",
       "      <th>median_arrival_delay</th>\n",
       "      <th>perc_3m_delay</th>\n",
       "      <th>perc_5m_delay</th>\n",
       "      <th>perc_10m_delay</th>\n",
       "      <th>count_dates_train</th>\n",
       "      <th>count_stops_train</th>\n",
       "      <th>first_date</th>\n",
       "      <th>last_date</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>arrival_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94489280513</td>\n",
       "      <td>REG</td>\n",
       "      <td>4096</td>\n",
       "      <td>ROMA TERMINI</td>\n",
       "      <td>FIRENZE S.M.N.</td>\n",
       "      <td>4.621205</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.281656</td>\n",
       "      <td>0.134740</td>\n",
       "      <td>88</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>07:02</td>\n",
       "      <td>10:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128849018888</td>\n",
       "      <td>REG</td>\n",
       "      <td>4565</td>\n",
       "      <td>FOLIGNO</td>\n",
       "      <td>ROMA TERMINI</td>\n",
       "      <td>0.478650</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>0.124060</td>\n",
       "      <td>0.041353</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>76</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>05:55</td>\n",
       "      <td>08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137438953510</td>\n",
       "      <td>REG</td>\n",
       "      <td>2116</td>\n",
       "      <td>GENOVA P.PRINCIPE</td>\n",
       "      <td>TORINO P.NUOVA</td>\n",
       "      <td>1.689368</td>\n",
       "      <td>-0.875000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>06:27</td>\n",
       "      <td>08:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146028888076</td>\n",
       "      <td>REG</td>\n",
       "      <td>12984</td>\n",
       "      <td>CATANIA CENTRALE</td>\n",
       "      <td>GIARRE RIPOSTO</td>\n",
       "      <td>0.499278</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.072797</td>\n",
       "      <td>0.019157</td>\n",
       "      <td>0.015326</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>14:40</td>\n",
       "      <td>15:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188978561024</td>\n",
       "      <td>REG</td>\n",
       "      <td>827</td>\n",
       "      <td>M N CADORNA</td>\n",
       "      <td>SARONNO</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>09:47</td>\n",
       "      <td>10:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>223338299438</td>\n",
       "      <td>REG</td>\n",
       "      <td>23209</td>\n",
       "      <td>MONTEBELLUNA</td>\n",
       "      <td>PADOVA</td>\n",
       "      <td>1.715833</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>09:46</td>\n",
       "      <td>10:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>309237645350</td>\n",
       "      <td>REG</td>\n",
       "      <td>10469</td>\n",
       "      <td>MILANO GRECO PIRELLI</td>\n",
       "      <td>STRADELLA</td>\n",
       "      <td>2.718519</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.348148</td>\n",
       "      <td>0.170370</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>75</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>13:47</td>\n",
       "      <td>15:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>386547056691</td>\n",
       "      <td>REG</td>\n",
       "      <td>20214</td>\n",
       "      <td>COLLEFERRO-SEGNI-PALIANO</td>\n",
       "      <td>ROMA TERMINI</td>\n",
       "      <td>0.820789</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.118280</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>19:15</td>\n",
       "      <td>20:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>412316860444</td>\n",
       "      <td>REG</td>\n",
       "      <td>21700</td>\n",
       "      <td>PUNTA RAISI</td>\n",
       "      <td>PALERMO CENTRALE</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.079861</td>\n",
       "      <td>0.038194</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>72</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>05:20</td>\n",
       "      <td>06:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>489626271804</td>\n",
       "      <td>REG</td>\n",
       "      <td>17631</td>\n",
       "      <td>FERRARA</td>\n",
       "      <td>RAVENNA</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>16:37</td>\n",
       "      <td>17:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_id train_class train_number train_departure_stop_name  \\\n",
       "0   94489280513         REG         4096              ROMA TERMINI   \n",
       "1  128849018888         REG         4565                   FOLIGNO   \n",
       "2  137438953510         REG         2116         GENOVA P.PRINCIPE   \n",
       "3  146028888076         REG        12984          CATANIA CENTRALE   \n",
       "4  188978561024         REG          827               M N CADORNA   \n",
       "5  223338299438         REG        23209              MONTEBELLUNA   \n",
       "6  309237645350         REG        10469      MILANO GRECO PIRELLI   \n",
       "7  386547056691         REG        20214  COLLEFERRO-SEGNI-PALIANO   \n",
       "8  412316860444         REG        21700               PUNTA RAISI   \n",
       "9  489626271804         REG        17631                   FERRARA   \n",
       "\n",
       "  train_arrival_stop_name  avg_arrival_delay  median_arrival_delay  \\\n",
       "0          FIRENZE S.M.N.           4.621205              1.071429   \n",
       "1            ROMA TERMINI           0.478650             -0.285714   \n",
       "2          TORINO P.NUOVA           1.689368             -0.875000   \n",
       "3          GIARRE RIPOSTO           0.499278             -0.333333   \n",
       "4                 SARONNO           0.000000              0.000000   \n",
       "5                  PADOVA           1.715833              1.250000   \n",
       "6               STRADELLA           2.718519              1.666667   \n",
       "7            ROMA TERMINI           0.820789              0.555556   \n",
       "8        PALERMO CENTRALE           0.814815              0.333333   \n",
       "9                 RAVENNA           1.000000              0.888889   \n",
       "\n",
       "   perc_3m_delay  perc_5m_delay  perc_10m_delay  count_dates_train  \\\n",
       "0       0.441558       0.281656        0.134740                 88   \n",
       "1       0.124060       0.041353        0.013158                 76   \n",
       "2       0.166667       0.104167        0.058333                 30   \n",
       "3       0.072797       0.019157        0.015326                 87   \n",
       "4       0.000000       0.000000        0.000000                 88   \n",
       "5       0.390000       0.130000        0.000000                 25   \n",
       "6       0.348148       0.170370        0.040000                 75   \n",
       "7       0.118280       0.008961        0.000000                 62   \n",
       "8       0.079861       0.038194        0.009259                 72   \n",
       "9       0.194444       0.009259        0.000000                 12   \n",
       "\n",
       "   count_stops_train  first_date   last_date departure_time arrival_time  \n",
       "0                 14  2023-01-02  2023-03-31          07:02        10:48  \n",
       "1                  7  2023-01-02  2023-03-31          05:55        08:00  \n",
       "2                  8  2023-01-01  2023-03-26          06:27        08:30  \n",
       "3                  3  2023-01-01  2023-03-31          14:40        15:15  \n",
       "4                  5  2023-01-01  2023-03-31          09:47        10:07  \n",
       "5                  4  2023-02-27  2023-03-31          09:46        10:33  \n",
       "6                  9  2023-01-02  2023-03-31          13:47        15:05  \n",
       "7                  9  2023-01-02  2023-03-31          19:15        20:13  \n",
       "8                 12  2023-01-07  2023-03-31          05:20        06:20  \n",
       "9                  9  2023-01-01  2023-03-26          16:37        17:48  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trains_stat4_pandas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: dataset_generated/data_train_index.csv (deflated 69%)\n"
     ]
    }
   ],
   "source": [
    "if SAVE_COMPUTATIONS :    \n",
    "    # store the file in a csv file  \n",
    "    df_trains_stat4_pandas.to_csv(\"dataset_generated/data_train_index.csv\", index=False)\n",
    "\n",
    "    # zip the file\n",
    "    !zip dataset_generated/data_train_index.zip dataset_generated/data_train_index.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we store the data in a better format, which is a folder in which each file is a train, and the filename is the train id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "# if the folder already exists, delete it\n",
    "if os.path.exists(\"renamed_csv_files\"):\n",
    "    shutil.rmtree(\"renamed_csv_files\")\n",
    "\n",
    "# create a new directory to store the renamed CSV files\n",
    "if not os.path.exists(\"renamed_csv_files\"):\n",
    "    os.mkdir(\"renamed_csv_files\")\n",
    "\n",
    "# loop through all directories in the \"data_train_stat/data_train_stat.csv\" directory that start with \"train_id=\"\n",
    "for dirpath, dirnames, filenames in os.walk(\"dataset_generated/data_train_stat/data_train_stat.csv\"):\n",
    "    for dirname in dirnames:\n",
    "        if dirname.startswith(\"train_id=\"):\n",
    "            # extract the ID from the directory name\n",
    "            id = dirname.split(\"=\")[1]\n",
    "            # loop through all CSV files in the directory\n",
    "            for filename in os.listdir(os.path.join(dirpath, dirname)):\n",
    "                if filename.endswith(\".csv\"):\n",
    "                    # rename the file to \"[ID].csv\" and move it to the \"renamed_csv_files\" directory\n",
    "                    src_path = os.path.join(dirpath, dirname, filename)\n",
    "                    dst_path = os.path.join(\"renamed_csv_files\", f\"{id}.csv\")\n",
    "                    shutil.copy(src_path, dst_path)\n",
    "\n",
    "\n",
    "# create a zip file containing the \"renamed_csv_files\" directory, the files have to be in a directory when unzipped\n",
    "shutil.make_archive(\"renamed_csv_files\", \"zip\", \"renamed_csv_files\")\n",
    "\n",
    "# delete the \"renamed_csv_files\" directory\n",
    "shutil.rmtree(\"renamed_csv_files\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Path of trains over a map\n",
    "Now that we have computed a dataset with the statistics for each train, in which we managed to extract the timetable, we can use it to plot the path of each train on a map. \n",
    "\n",
    "The task of matching information of a train, with its exact journey on the railway is a complex task. The algorithm developed by [Bast and Brosi (2019)](https://ad-publications.cs.uni-freiburg.de/SIGSPATIAL_Sparse%20map%20matching%202018.pdf) matches the GTFS schedule of a train with the OpenStreetMap railway network. Thankfully, they published the code of this algorithm on GitHub. Their library takes a GTFS schedule of a train and a railway network in OpenStreetMap format and returns the most likely journey of the train on the railway network in `shapefile` format. GTFS is a standard format for public transport schedules, promoted by Google.\n",
    "\n",
    "First, we need to generate a GTFS timetable for our trains. Then, we can run the algorithm a produce a shapefile for each train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trains_timetable = df_trains_stat3 \\\n",
    "    .select(\"train_id\", \"train_class\", \"train_number\", \"train_departure_stop_name\", \"train_arrival_stop_name\", \"stop_number\", \"stop_name\", \"stop_time\", \"stop_lat\", \"stop_lon\")\n",
    "\n",
    "# need to join with the stops to get stop_id that we have lost on the way\n",
    "trains_timetable = trains_timetable \\\n",
    "    .join(stops, on=[\"stop_name\", \"stop_lat\", \"stop_lon\"], how=\"inner\")\n",
    "\n",
    "trains_timetable_pandas = trains_timetable.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>train_id</th>\n",
       "      <th>train_class</th>\n",
       "      <th>train_number</th>\n",
       "      <th>train_departure_stop_name</th>\n",
       "      <th>train_arrival_stop_name</th>\n",
       "      <th>stop_number</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name_short</th>\n",
       "      <th>stop_id_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAVONA</td>\n",
       "      <td>44.306892</td>\n",
       "      <td>8.470259</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>1</td>\n",
       "      <td>06:28</td>\n",
       "      <td>S04801</td>\n",
       "      <td>Savona</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENOVA VOLTRI</td>\n",
       "      <td>44.428467</td>\n",
       "      <td>8.758163</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>2</td>\n",
       "      <td>06:48</td>\n",
       "      <td>S04534</td>\n",
       "      <td>Genova Voltri</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENOVA SESTRI PONENTE</td>\n",
       "      <td>44.422374</td>\n",
       "      <td>8.847707</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>3</td>\n",
       "      <td>07:02</td>\n",
       "      <td>S04537</td>\n",
       "      <td>Genova Sestri P.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENOVA SAMPIERDARENA</td>\n",
       "      <td>44.413102</td>\n",
       "      <td>8.887271</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>4</td>\n",
       "      <td>07:13</td>\n",
       "      <td>S04220</td>\n",
       "      <td>GE Sampierdarena</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENOVA P.PRINCIPE</td>\n",
       "      <td>44.417784</td>\n",
       "      <td>8.920700</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>5</td>\n",
       "      <td>07:20</td>\n",
       "      <td>S04700</td>\n",
       "      <td>Genova P.Princ.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GENOVA BRIGNOLE</td>\n",
       "      <td>44.407213</td>\n",
       "      <td>8.947553</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>6</td>\n",
       "      <td>07:31</td>\n",
       "      <td>S04702</td>\n",
       "      <td>Genova Brignole</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GENOVA QUARTO DEI MILLE</td>\n",
       "      <td>44.388607</td>\n",
       "      <td>8.995970</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>7</td>\n",
       "      <td>07:41</td>\n",
       "      <td>S04704</td>\n",
       "      <td>Genova Quarto</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GENOVA NERVI</td>\n",
       "      <td>44.381271</td>\n",
       "      <td>9.039895</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>8</td>\n",
       "      <td>07:48</td>\n",
       "      <td>S04707</td>\n",
       "      <td>Genova Nervi</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RECCO</td>\n",
       "      <td>44.361215</td>\n",
       "      <td>9.146788</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>9</td>\n",
       "      <td>08:08</td>\n",
       "      <td>S04714</td>\n",
       "      <td>Recco</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SARONNO</td>\n",
       "      <td>45.625309</td>\n",
       "      <td>9.030839</td>\n",
       "      <td>1</td>\n",
       "      <td>REG</td>\n",
       "      <td>876</td>\n",
       "      <td>SARONNO</td>\n",
       "      <td>M N CADORNA</td>\n",
       "      <td>1</td>\n",
       "      <td>19:53</td>\n",
       "      <td>S01933</td>\n",
       "      <td>SARONNO</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 stop_name   stop_lat  stop_lon  train_id train_class  \\\n",
       "0                   SAVONA  44.306892  8.470259         0         REG   \n",
       "1            GENOVA VOLTRI  44.428467  8.758163         0         REG   \n",
       "2    GENOVA SESTRI PONENTE  44.422374  8.847707         0         REG   \n",
       "3     GENOVA SAMPIERDARENA  44.413102  8.887271         0         REG   \n",
       "4        GENOVA P.PRINCIPE  44.417784  8.920700         0         REG   \n",
       "5          GENOVA BRIGNOLE  44.407213  8.947553         0         REG   \n",
       "6  GENOVA QUARTO DEI MILLE  44.388607  8.995970         0         REG   \n",
       "7             GENOVA NERVI  44.381271  9.039895         0         REG   \n",
       "8                    RECCO  44.361215  9.146788         0         REG   \n",
       "9                  SARONNO  45.625309  9.030839         1         REG   \n",
       "\n",
       "  train_number train_departure_stop_name train_arrival_stop_name  stop_number  \\\n",
       "0        22821                    SAVONA                   RECCO            1   \n",
       "1        22821                    SAVONA                   RECCO            2   \n",
       "2        22821                    SAVONA                   RECCO            3   \n",
       "3        22821                    SAVONA                   RECCO            4   \n",
       "4        22821                    SAVONA                   RECCO            5   \n",
       "5        22821                    SAVONA                   RECCO            6   \n",
       "6        22821                    SAVONA                   RECCO            7   \n",
       "7        22821                    SAVONA                   RECCO            8   \n",
       "8        22821                    SAVONA                   RECCO            9   \n",
       "9          876                   SARONNO             M N CADORNA            1   \n",
       "\n",
       "  stop_time stop_id   stop_name_short  stop_id_region  \n",
       "0     06:28  S04801            Savona             2.0  \n",
       "1     06:48  S04534     Genova Voltri             2.0  \n",
       "2     07:02  S04537  Genova Sestri P.             2.0  \n",
       "3     07:13  S04220  GE Sampierdarena             2.0  \n",
       "4     07:20  S04700   Genova P.Princ.             2.0  \n",
       "5     07:31  S04702   Genova Brignole             2.0  \n",
       "6     07:41  S04704     Genova Quarto             2.0  \n",
       "7     07:48  S04707      Genova Nervi             2.0  \n",
       "8     08:08  S04714             Recco             2.0  \n",
       "9     19:53  S01933           SARONNO             1.0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trains_timetable_pandas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# delete folder if it exists\n",
    "import shutil\n",
    "if os.path.exists(\"gtfs\"):\n",
    "    shutil.rmtree(\"gtfs\")\n",
    "\n",
    "# create folder gtfs \n",
    "if not os.path.exists(\"gtfs\"):\n",
    "    os.mkdir(\"gtfs\")\n",
    "\n",
    "# 1. Create the agency.txt file\n",
    "agency = {\n",
    "    \"agency_id\": \"1\",\n",
    "    \"agency_name\": \"Trenitalia\",\n",
    "    \"agency_url\": \"https://www.trenitalia.com\",\n",
    "    \"agency_timezone\": \"Europe/Rome\",\n",
    "    \"agency_lang\": \"it\",\n",
    "    \"agency_phone\": \"\"\n",
    "}\n",
    "agency = pd.DataFrame(agency, index=[0])\n",
    "agency.to_csv(\"gtfs/agency.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. create routes.txt\n",
    "# docs: https://gtfs.org/schedule/reference/#routestxt\n",
    "\n",
    "\n",
    "routes = pd.DataFrame()\n",
    "\n",
    "# get unique tuples (train_id, train_class, train_number)\n",
    "train_ids = trains_timetable_pandas[[\"train_id\", \"train_class\", \"train_number\"]].drop_duplicates()\n",
    "\n",
    "routes[\"route_id\"] = train_ids[\"train_id\"]\n",
    "routes[\"route_short_name\"] = train_ids[\"train_class\"] + \" \" + train_ids[\"train_number\"]\n",
    "routes[\"route_long_name\"] = train_ids[\"train_class\"] + \" \" + train_ids[\"train_number\"]\n",
    "\n",
    "color_mapper = {\n",
    "    \"IC\": \"E0A434\",\n",
    "    \"REG\": \"036864\",\n",
    "    \"ICN\": \"E0A434\",\n",
    "    \"AV\": \"DC263B\",\n",
    "    \"EC\": \"DC263B\",\n",
    "}\n",
    "\n",
    "routes[\"agency_id\"] = \"1\"\n",
    "routes[\"route_type\"] = \"2\" # 2 is train\n",
    "\n",
    "routes[\"route_color\"] = routes[\"route_short_name\"].apply(lambda x: color_mapper[x.split(\" \")[0]])\n",
    "\n",
    "routes.to_csv(\"gtfs/routes.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. create stops.txt\n",
    "# docs: https://gtfs.org/schedule/reference/#stopstxt\n",
    "stops_gtfs = trains_timetable_pandas[[\"stop_id\", \"stop_name\", \"stop_lat\", \"stop_lon\"]].drop_duplicates()\n",
    "stops_gtfs.to_csv(\"gtfs/stops.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Tough one, create calendar.txt and trips.txt\n",
    "# calendar describes the span of a service\n",
    "# trips describes the service for a particular route\n",
    "\n",
    "# 4a: create calendar.txt\n",
    "# docs: https://gtfs.org/schedule/reference/#calendartxt\n",
    "calendar = {\n",
    "    # we just create a service that runs every day for the whole year\n",
    "    \"service_id\": \"1\",\n",
    "    \"monday\": \"1\",\n",
    "    \"tuesday\": \"1\",\n",
    "    \"wednesday\": \"1\",\n",
    "    \"thursday\": \"1\",\n",
    "    \"friday\": \"1\",\n",
    "    \"saturday\": \"1\",\n",
    "    \"sunday\": \"1\",\n",
    "    \"start_date\": \"19000101\",\n",
    "    \"end_date\": \"21000101\",\n",
    "}\n",
    "calendar = pd.DataFrame(calendar, index=[0])\n",
    "calendar.to_csv(\"gtfs/calendar.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4b: create trips.txt\n",
    "# docs: https://gtfs.org/schedule/reference/#tripstxt\n",
    "# trips = {\n",
    "#     \"route_id\": \"1\",\n",
    "#     \"service_id\": \"1\",\n",
    "#     \"trip_id\": \"1\",\n",
    "#     \"trip_headsign\": query_7[\"train_class\"] + \" \" + query_7[\"train_number\"],\n",
    "#     \"trip_short_name\": query_7[\"train_class\"] + \" \" + query_7[\"train_number\"],\n",
    "#     \"direction_id\": \"\",\n",
    "#     \"block_id\": \"\",\n",
    "#     \"shape_id\": \"\",\n",
    "#     \"wheelchair_accessible\": \"\",\n",
    "#     \"bikes_allowed\": \"\",\n",
    "# }\n",
    "\n",
    "# trips = pd.DataFrame(trips, index=[0])\n",
    "\n",
    "trips = pd.DataFrame()\n",
    "\n",
    "trips[\"route_id\"] = train_ids[\"train_id\"]\n",
    "trips[\"service_id\"] = \"1\"\n",
    "trips[\"trip_id\"] = train_ids[\"train_id\"]\n",
    "trips[\"trip_headsign\"] = train_ids[\"train_class\"] + \" \" + train_ids[\"train_number\"]\n",
    "trips[\"trip_short_name\"] = train_ids[\"train_class\"] + \" \" + train_ids[\"train_number\"]\n",
    "trips[\"direction_id\"] = \"\"\n",
    "trips[\"block_id\"] = \"\"\n",
    "trips[\"shape_id\"] = \"\"\n",
    "trips[\"wheelchair_accessible\"] = \"\"\n",
    "trips[\"bikes_allowed\"] = \"\"\n",
    "\n",
    "\n",
    "trips.to_csv(\"gtfs/trips.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>train_id</th>\n",
       "      <th>train_class</th>\n",
       "      <th>train_number</th>\n",
       "      <th>train_departure_stop_name</th>\n",
       "      <th>train_arrival_stop_name</th>\n",
       "      <th>stop_number</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name_short</th>\n",
       "      <th>stop_id_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAVONA</td>\n",
       "      <td>44.306892</td>\n",
       "      <td>8.470259</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>1</td>\n",
       "      <td>06:28</td>\n",
       "      <td>S04801</td>\n",
       "      <td>Savona</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENOVA VOLTRI</td>\n",
       "      <td>44.428467</td>\n",
       "      <td>8.758163</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>2</td>\n",
       "      <td>06:48</td>\n",
       "      <td>S04534</td>\n",
       "      <td>Genova Voltri</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENOVA SESTRI PONENTE</td>\n",
       "      <td>44.422374</td>\n",
       "      <td>8.847707</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>3</td>\n",
       "      <td>07:02</td>\n",
       "      <td>S04537</td>\n",
       "      <td>Genova Sestri P.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENOVA SAMPIERDARENA</td>\n",
       "      <td>44.413102</td>\n",
       "      <td>8.887271</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>4</td>\n",
       "      <td>07:13</td>\n",
       "      <td>S04220</td>\n",
       "      <td>GE Sampierdarena</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENOVA P.PRINCIPE</td>\n",
       "      <td>44.417784</td>\n",
       "      <td>8.920700</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>5</td>\n",
       "      <td>07:20</td>\n",
       "      <td>S04700</td>\n",
       "      <td>Genova P.Princ.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GENOVA BRIGNOLE</td>\n",
       "      <td>44.407213</td>\n",
       "      <td>8.947553</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>6</td>\n",
       "      <td>07:31</td>\n",
       "      <td>S04702</td>\n",
       "      <td>Genova Brignole</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GENOVA QUARTO DEI MILLE</td>\n",
       "      <td>44.388607</td>\n",
       "      <td>8.995970</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>7</td>\n",
       "      <td>07:41</td>\n",
       "      <td>S04704</td>\n",
       "      <td>Genova Quarto</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GENOVA NERVI</td>\n",
       "      <td>44.381271</td>\n",
       "      <td>9.039895</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>8</td>\n",
       "      <td>07:48</td>\n",
       "      <td>S04707</td>\n",
       "      <td>Genova Nervi</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RECCO</td>\n",
       "      <td>44.361215</td>\n",
       "      <td>9.146788</td>\n",
       "      <td>0</td>\n",
       "      <td>REG</td>\n",
       "      <td>22821</td>\n",
       "      <td>SAVONA</td>\n",
       "      <td>RECCO</td>\n",
       "      <td>9</td>\n",
       "      <td>08:08</td>\n",
       "      <td>S04714</td>\n",
       "      <td>Recco</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SARONNO</td>\n",
       "      <td>45.625309</td>\n",
       "      <td>9.030839</td>\n",
       "      <td>1</td>\n",
       "      <td>REG</td>\n",
       "      <td>876</td>\n",
       "      <td>SARONNO</td>\n",
       "      <td>M N CADORNA</td>\n",
       "      <td>1</td>\n",
       "      <td>19:53</td>\n",
       "      <td>S01933</td>\n",
       "      <td>SARONNO</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 stop_name   stop_lat  stop_lon  train_id train_class  \\\n",
       "0                   SAVONA  44.306892  8.470259         0         REG   \n",
       "1            GENOVA VOLTRI  44.428467  8.758163         0         REG   \n",
       "2    GENOVA SESTRI PONENTE  44.422374  8.847707         0         REG   \n",
       "3     GENOVA SAMPIERDARENA  44.413102  8.887271         0         REG   \n",
       "4        GENOVA P.PRINCIPE  44.417784  8.920700         0         REG   \n",
       "5          GENOVA BRIGNOLE  44.407213  8.947553         0         REG   \n",
       "6  GENOVA QUARTO DEI MILLE  44.388607  8.995970         0         REG   \n",
       "7             GENOVA NERVI  44.381271  9.039895         0         REG   \n",
       "8                    RECCO  44.361215  9.146788         0         REG   \n",
       "9                  SARONNO  45.625309  9.030839         1         REG   \n",
       "\n",
       "  train_number train_departure_stop_name train_arrival_stop_name  stop_number  \\\n",
       "0        22821                    SAVONA                   RECCO            1   \n",
       "1        22821                    SAVONA                   RECCO            2   \n",
       "2        22821                    SAVONA                   RECCO            3   \n",
       "3        22821                    SAVONA                   RECCO            4   \n",
       "4        22821                    SAVONA                   RECCO            5   \n",
       "5        22821                    SAVONA                   RECCO            6   \n",
       "6        22821                    SAVONA                   RECCO            7   \n",
       "7        22821                    SAVONA                   RECCO            8   \n",
       "8        22821                    SAVONA                   RECCO            9   \n",
       "9          876                   SARONNO             M N CADORNA            1   \n",
       "\n",
       "  stop_time stop_id   stop_name_short  stop_id_region  \n",
       "0     06:28  S04801            Savona             2.0  \n",
       "1     06:48  S04534     Genova Voltri             2.0  \n",
       "2     07:02  S04537  Genova Sestri P.             2.0  \n",
       "3     07:13  S04220  GE Sampierdarena             2.0  \n",
       "4     07:20  S04700   Genova P.Princ.             2.0  \n",
       "5     07:31  S04702   Genova Brignole             2.0  \n",
       "6     07:41  S04704     Genova Quarto             2.0  \n",
       "7     07:48  S04707      Genova Nervi             2.0  \n",
       "8     08:08  S04714             Recco             2.0  \n",
       "9     19:53  S01933           SARONNO             1.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trains_timetable_pandas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. create stop_times.txt\n",
    "# docs: https://gtfs.org/schedule/reference/#stop_timestxt\n",
    "# convert stop_departure_time to HH:MM:SS using pyspark function\n",
    "\n",
    "# stop_times: pd.DataFrame = train_data_day_df[[\"stop_id\", \"stop_departure_time\", \"stop_arrival_time\"]] \\\n",
    "#     .rename(columns={\"stop_id\": \"stop_id\", \"stop_departure_time\": \"departure_time\", \"stop_arrival_time\": \"arrival_time\"})\n",
    "\n",
    "\n",
    "# def convert_to_hh_mm_ss(time):\n",
    "    \n",
    "                                                                                                            \n",
    "# # add column with stop_sequence\n",
    "# stop_times[\"stop_sequence\"] = stop_times.index + 1\n",
    "# # add column with trip_id\n",
    "# stop_times[\"trip_id\"] = \"1\"\n",
    "# # put departure time of the last stop equal to the arrival time\n",
    "# stop_times.loc[stop_times.index[-1], \"departure_time\"] = stop_times.loc[stop_times.index[-1], \"arrival_time\"]\n",
    "# store it\n",
    "\n",
    "stop_times_gtfs = pd.DataFrame()\n",
    "\n",
    "stop_times_gtfs[\"trip_id\"] = trains_timetable_pandas[\"train_id\"]\n",
    "stop_times_gtfs[\"arrival_time\"] = trains_timetable_pandas[\"stop_time\"].apply(lambda x: x + \":00\")\n",
    "stop_times_gtfs[\"departure_time\"] = trains_timetable_pandas[\"stop_time\"].apply(lambda x: x + \":00\")\n",
    "stop_times_gtfs[\"stop_id\"] = trains_timetable_pandas[\"stop_id\"]\n",
    "stop_times_gtfs[\"stop_sequence\"] = trains_timetable_pandas[\"stop_number\"]\n",
    "\n",
    "stop_times_gtfs.to_csv(\"gtfs/stop_times.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a zip using libzip\n",
    "import zipfile\n",
    "zf = zipfile.ZipFile('gtfs.zip', mode='w')\n",
    "try:\n",
    "    zf.write(\"gtfs/agency.txt\")\n",
    "    zf.write(\"gtfs/calendar.txt\")\n",
    "    zf.write(\"gtfs/routes.txt\")\n",
    "    zf.write(\"gtfs/stops.txt\")\n",
    "    zf.write(\"gtfs/stop_times.txt\")\n",
    "    zf.write(\"gtfs/trips.txt\")\n",
    "finally:\n",
    "    zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the algorithm\n",
    "We downloaded and installed pfaedle as well as an OSM dump for Italy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/giacomoorsi/Documents/EPFL/MA4/Data Visualization/project-2023-rail-runners/data'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current folder name\n",
    "# import os\n",
    "# os.path.basename(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-21 11:28:59.404] INFO : Reading GTFS feed gtfs ...\n",
      "[2023-05-21 11:28:59.469] INFO : Matching shapes for mots <bus>\n",
      "[2023-05-21 11:28:59.765] INFO : Matched 0 trips in 0.131 ms.\n",
      "[2023-05-21 11:28:59.766] INFO : Matching shapes for mots <ferry>\n",
      "[2023-05-21 11:29:00.057] INFO : Matched 0 trips in 0.1 ms.\n",
      "[2023-05-21 11:29:00.058] INFO : Matching shapes for mots <tram>, <subway>\n",
      "[2023-05-21 11:29:00.363] INFO : Matched 0 trips in 0.143 ms.\n",
      "[2023-05-21 11:29:00.363] INFO : Matching shapes for mots <coach>\n",
      "[2023-05-21 11:29:00.658] INFO : Matched 0 trips in 0.106 ms.\n",
      "[2023-05-21 11:29:00.658] INFO : Matching shapes for mots <funicular>\n",
      "[2023-05-21 11:29:00.949] INFO : Matched 0 trips in 0.089 ms.\n",
      "[2023-05-21 11:29:00.949] INFO : Matching shapes for mots <rail>\n",
      "[2023-05-21 11:29:00.956] INFO : Reading OSM file /Users/giacomoorsi/Downloads/italy-latest.osm ... \n",
      "[2023-05-21 11:29:01.048] ERROR: Could not parse OSM data, reason was:\n",
      "/Users/giacomoorsi/Downloads/italy-latest.osm at position 0: could not open file\n"
     ]
    }
   ],
   "source": [
    "\"\"\"pfaedle -x ~/Downloads/italy-latest.osm {}\"\"\".format(os.path.join(os.getcwd(), \"gtfs\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the shapes in the \"shapes.txt\" file, we want to separate all those files into one file for each train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shape_id</th>\n",
       "      <th>shape_pt_lat</th>\n",
       "      <th>shape_pt_lon</th>\n",
       "      <th>shape_pt_sequence</th>\n",
       "      <th>shape_dist_traveled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shp_2_1</td>\n",
       "      <td>45.060719</td>\n",
       "      <td>12.054278</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shp_2_1</td>\n",
       "      <td>45.060688</td>\n",
       "      <td>12.055992</td>\n",
       "      <td>2</td>\n",
       "      <td>134.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shp_2_1</td>\n",
       "      <td>45.060673</td>\n",
       "      <td>12.056358</td>\n",
       "      <td>3</td>\n",
       "      <td>163.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shp_2_1</td>\n",
       "      <td>45.060551</td>\n",
       "      <td>12.057537</td>\n",
       "      <td>4</td>\n",
       "      <td>257.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shp_2_1</td>\n",
       "      <td>45.060535</td>\n",
       "      <td>12.058019</td>\n",
       "      <td>5</td>\n",
       "      <td>295.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shp_2_1</td>\n",
       "      <td>45.060532</td>\n",
       "      <td>12.058478</td>\n",
       "      <td>6</td>\n",
       "      <td>331.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shp_2_1</td>\n",
       "      <td>45.060558</td>\n",
       "      <td>12.059030</td>\n",
       "      <td>7</td>\n",
       "      <td>374.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shp_2_1</td>\n",
       "      <td>45.060612</td>\n",
       "      <td>12.059502</td>\n",
       "      <td>8</td>\n",
       "      <td>412.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>shp_2_1</td>\n",
       "      <td>45.060711</td>\n",
       "      <td>12.060016</td>\n",
       "      <td>9</td>\n",
       "      <td>454.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shp_2_1</td>\n",
       "      <td>45.060802</td>\n",
       "      <td>12.060353</td>\n",
       "      <td>10</td>\n",
       "      <td>482.701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  shape_dist_traveled\n",
       "0  shp_2_1     45.060719     12.054278                  1                0.000\n",
       "1  shp_2_1     45.060688     12.055992                  2              134.766\n",
       "2  shp_2_1     45.060673     12.056358                  3              163.568\n",
       "3  shp_2_1     45.060551     12.057537                  4              257.302\n",
       "4  shp_2_1     45.060535     12.058019                  5              295.222\n",
       "5  shp_2_1     45.060532     12.058478                  6              331.315\n",
       "6  shp_2_1     45.060558     12.059030                  7              374.774\n",
       "7  shp_2_1     45.060612     12.059502                  8              412.392\n",
       "8  shp_2_1     45.060711     12.060016                  9              454.289\n",
       "9  shp_2_1     45.060802     12.060353                 10              482.701"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "shapes_gtfs = pd.read_csv(\"gtfs-out/shapes.txt\")\n",
    "trips_gtfs = pd.read_csv(\"gtfs-out/trips.txt\")\n",
    "\n",
    "shapes_gtfs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_gtfs = trips_gtfs[[\"trip_id\",\"shape_id\"]]\n",
    "# merge columns on shape_id\n",
    "shapes_gtfs_merged = shapes_gtfs.merge(trips_gtfs, on=\"shape_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of distinct trains is  9983 while the number of distinct shapes is  2707\n"
     ]
    }
   ],
   "source": [
    "# drop shape_id\n",
    "print(\"The number of distinct trains is \", shapes_gtfs_merged[\"trip_id\"].nunique(), \"while the number of distinct shapes is \", shapes_gtfs_merged[\"shape_id\"].nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could save some space by storing the shapes independently from the trains, since there's multiple trains that share the same shape. However, to keep the frontend of the website simple, we decided to store the shape of each train in a separated file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1236950581288, 1322849927205, 1357209665555, ...,  893353197609,\n",
       "        996432412709, 1142461300786])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(shapes_gtfs_merged[\"trip_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9983/9983 [00:46<00:00, 215.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# delete folder if exists\n",
    "import shutil\n",
    "if os.path.exists(\"dataset_generated/trains_shapes\"):\n",
    "    shutil.rmtree(\"dataset_generated/trains_shapes\")\n",
    "\n",
    "# create folder\n",
    "os.mkdir(\"dataset_generated/trains_shapes\")\n",
    "\n",
    "# for each trid_id, save all the corrisponding shapes in a file\n",
    "for trip_id in tqdm(pd.unique(shapes_gtfs_merged[\"trip_id\"])):\n",
    "    shapes_gtfs_merged[shapes_gtfs_merged[\"trip_id\"] == trip_id][[\"shape_pt_lat\", \"shape_pt_lon\"]].to_csv(\"dataset_generated/trains_shapes/{}.csv\".format(trip_id), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/giacomoorsi/Documents/EPFL/MA4/DataVisualization/project-2023-rail-runners/data/dataset_generated/trains_shapes.zip'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip the folder with shutil\n",
    "shutil.make_archive(\"dataset_generated/trains_shapes\", 'zip', \"dataset_generated/trains_shapes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrenitaliaSpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
